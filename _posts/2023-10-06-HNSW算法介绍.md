---
layout: post 
title:  "HNSW算法介绍"
date:   2023-10-06 20:33:29 +0800 
author: "Shi Yinong"
tags:  技术杂谈
excerpt_separator: <!--more-->
---
HNSW是目前在工业界应用最多的向量检索算法，如Faiss、Vespa、Elastic Search中，都使用了HNSW来构建向量索引。
本篇文章就来详细的介绍下HNSW算法。<!--more-->

<!-- TOC -->
  * [一、HNSW是什么](#一hnsw是什么)
  * [二、构建HNSW](#二构建hnsw)
    * [1. 层内搜索算法](#1-层内搜索算法)
    * [2. 插入算法](#2-插入算法)
      * [a. 节点的最大层数](#a-节点的最大层数)
      * [b. 寻找邻接点](#b-寻找邻接点)
      * [c. 最优邻接点选择](#c-最优邻接点选择)
    * [3. KNN搜索算法](#3-knn搜索算法)
  * [三、我的理解](#三我的理解)
    * [1. KNN搜索时间复杂度](#1-knn搜索时间复杂度)
    * [2. layer的作用](#2-layer的作用)
    * [3. 参数选择](#3-参数选择)
  * [四、总结](#四总结)
    * [相比NSW，有哪些提升？](#相比nsw有哪些提升)
    * [有哪些问题？](#有哪些问题)
<!-- TOC -->

## 一、HNSW是什么
Hierarchical Navigable Small World(HNSW)，如下图所示，是一个多层的图结构，每一层都是一个NSW图，因此理解NSW是理解HNSW的前提，
关于NSW可以参考：[《NSW算法介绍》]({% post_url 2023-10-01-NSW算法介绍 %})。

<img height="430" src="\assets\hnsw-arch.png" width="350"/>

层数越高，该层节点数就越少，呈指数下降，而最底层（第0层）则包含了全部的节点。高层的layer节点少，稀疏的分布在向量空间中，有助于快速的将搜索结果定位到一个较小的范围内；
而低层的layer中节点分布密集，有助于精准的进行搜索。

## 二、构建HNSW

这里给出Golang版本的代码实现：

[https://github.com/shiyinong/hnsw-go/blob/main/algo/hnsw/hnsw.go](https://github.com/shiyinong/hnsw-go/blob/main/algo/hnsw/hnsw.go)

### 1. 层内搜索算法

这个算法其实就是NSW中的搜索算法的改进版，伪代码如下图所示：

<img height="470" src="\assets\hnsw_search_layer.png" width="450"/>

这里其实和NSW基本思路是一致的，有几个改进点：
1. entry point不再是随机获取，而是作为算法的输入；
2. 不再像NSW那样进行m轮的循环搜索，而是通过ef参数来平衡效率和精度；
3. 增加了剪枝条件，如果点c与当前点q的距离，大于results中第k个节点与点q的距离，那么说明点c就不需要作为候选节点了，可以直接丢弃（伪代码第13行）。

### 2. 插入算法

伪代码如下图所示：

<img height="540" src="\assets\hnsw_alg1.png" width="450"/>

#### a. 节点的最大层数

新节点插入索引之，前首先要确定节点的最大层数，论文中通过实验，得出了最优的节点最大层数计算方式，M是节点在每层的最大邻接点数量：

$$
maxL=\frac{-ln(unif(0...1))}{ln(M)}
$$

随机构造100万的数据，M取10，得到的每层的节点数量分布如下所示，横坐标是layer，纵坐标是节点数：

<img height="250" src="\assets\hnsw_node_count_of_layer.png" width="400"/>

可以看到随着层数的增加，每层的节点数量呈指数下降。

#### b. 寻找邻接点

从HNSW的最高层开始搜索，从最高层到第maxL层，每一层只搜索top1即可，当前层搜索到的top1，作为下一层搜索时的entry point，直到搜索到maxL层。

从第maxL层 到 第0层，都要搜索topK，然后在每一层建立当前点和邻接点的双向连接，这里和NSW不同的之处在于，NSW中是不限制节点的邻接点数量的，
但在HNSW中，当一个节点的邻接点数超过M时，就要进行最优邻接点选择了。

#### c. 最优邻接点选择

伪代码如下图所示：

<img height="130" src="\assets\hnsw_simple_algo.png" width="450"/>

<img height="550" src="\assets\hnsw_heuristic_algo.png" width="450"/>

论文中给出了两种方式：
1. simple模式。非常简单，直接取按照邻接点距本节点的距离，取最近的M个节点作为本节点的邻接点；
2. heuristic模式。simple模式其实只考虑了邻接点和本节点的距离，并没有考虑邻接点和其他邻接点的距离，而heuristic模式则同时考虑了这两种距离。
它的核心思路就是：**如果邻接点e与当前点q的距离，小于e与其他所有符合要求的邻接点的距离，那么说明e是符合要求的邻接点；否则就要把e丢弃**。
这样做的好处就是，对于存在cluster的数据集，可以避免邻接点全部都在同一个cluster中。

论文中通过实验给出结论，对于不存在cluster的数据集，simple和heuristic这两种方式差别不大；而对于存在cluster的数据集，simple模式几乎不可用，
而heuristic模式则完全不受cluster的影响，如下图所示：

<img height="250" src="\assets\hnsw_simple_heuristic.png" width="300"/>

### 3. KNN搜索算法

伪代码如下图所示：

<img height="300" src="\assets\hnsw_query_algo.png" width="450"/>

和插入算法比较类似，从最高层开始搜索，每层只搜索top1，前一层的top1作为当前层的entry point，直到搜索到第0层，需要搜索topK。

## 三、我的理解

### 1. KNN搜索时间复杂度

层内搜索算法的时间复杂度由两个因素决定，搜索步数（hop count）以及节点的度数（邻接点数量），二者的乘积就是总体的时间复杂度。
在HNSW中节点的度数是固定的常量，我们通过最优邻接点算法来保证的。而搜索步数，论文作者从理论角度上推出了它的时间复杂度是常数（关于这一点，其实我并没有研究清楚-_-!）。
因此层内搜索算法整体的时间复杂度是常数的。而HNSW的层数是对数级别的，因此KNN搜索的时间复杂度整体也是对数级别的。

通过实验也证明了这一点，如下图所示，可以看到NSW呈现`$log^2(n)$`复杂度，而HNSW呈现`$log(n)$`复杂度。

<img height="290" src="\assets\hnsw_vs_nsw.png" width="710"/>

### 2. layer的作用

HNSW与NSW相比一个最大的提升，就在于它是一个多层的图结构，这一点从命名上就能看出来。layer的作用有以下几点：
1. layer能够加速搜索，通过高层的layer快速将搜索空间缩小，再在底层的layer中精准搜索。
2. 构建时不再需要节点乱序输入。NSW中提到过，构建时必须乱序输入节点，否则无法生成长边。而HNSW则无此要求，即使顺序输入无法生成长边也没关系，
HNSW加速搜索本来也不完全依赖长边。
3. 不再需要随机选择entry point。NSW的搜索算法之所以需要循环m轮，一个原因就是随机选择的entry point无法保证精度。而HNSW中，选择层数最高的节点
作为entry point即可。

### 3. 参数选择

1. M：邻接点的最大数量。该值越大，精度越高，效率越低。反之精度越低，效率越高。作者给出的建议取值范围：[5, 48]，数据的维度越大，M取值就应该越大。
2. ef：搜索时的结果集数量。该值越大，精度越高，效率越低。反之精度越低，效率越高。
3. efConf：插入时，搜索待插入点的邻接点时的结果集数量。该值越大，精度越高，效率越低。反之精度越低，效率越高。

## 四、总结

### 相比NSW，有哪些提升？
1. 得益于多层结构，搜索的时间复杂度由`$log^2(n)$`降低至`$log(n)$`。
2. 构建时对节点插入顺序没有要求。
3. NSW因为存在随机选择entry point，因此它的搜索结果实际上是不确定的，多次进行相同的搜索，结果可能都不同，而HNSW则没有该问题。

### 有哪些问题？
1. 参数很难选择，牵一发而动全身。
2. 作者在文章最后提到，HNSW不易于分布式实现。不过，目前一些开源向量数据库都对HNSW做了分布式方面的改进，是能够支持分布式的。